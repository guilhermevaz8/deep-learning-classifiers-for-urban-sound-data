{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "838c7a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfclass = pd.read_csv(r'UrbanSound8K.csv')\n",
    "dfclass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53e6f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import librosa\n",
    "import random\n",
    "import sys\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "492613a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8732\n",
      "873\n"
     ]
    }
   ],
   "source": [
    "FOLDS_PATH = \"../UrbanSound8K/audio/\"\n",
    "all_audio_paths = []\n",
    "all_labels = []\n",
    "\n",
    "# Supondo que você tenha um DataFrame df com as colunas 'file_path' e 'label'\n",
    "# Organize os dados de cada fold em listas separadas\n",
    "\n",
    "i=0\n",
    "# Organize os dados de cada fold em listas separadas\n",
    "fold_data = {f'fold{i}': {'all_paths': [], 'paths': [], 'labels': []} for i in range(1, 11)}\n",
    "\n",
    "for index, row in dfclass.iterrows():\n",
    "    i+=1\n",
    "    fold = row['fold']\n",
    "    file_path = os.path.join(FOLDS_PATH, f\"fold{fold}\", row[\"slice_file_name\"])\n",
    "    fold_data[f\"fold{fold}\"]['all_paths'].append(file_path)\n",
    "    fold_data[f\"fold{fold}\"]['labels'].append(row['classID'])\n",
    "\n",
    "print(i)\n",
    "print(len(fold_data['fold1']['all_paths']))\n",
    "\n",
    "# Dividir aleatoriamente cada fold em metades\n",
    "for fold, data in fold_data.items():\n",
    "    combined = list(zip(data['all_paths'], data['labels']))\n",
    "    random.shuffle(combined)\n",
    "    paths, labels = zip(*combined)\n",
    "    split_index = len(paths)//100\n",
    "    data['paths'] = paths[:split_index]\n",
    "    data['labels'] = labels[:split_index]\n",
    "for key in fold_data:\n",
    "    fold_data[key].pop('all_paths')\n",
    "del data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cafd5320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e0bad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "def create_model(input_shape, num_classes=10):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, 5, activation='relu', input_shape=(88200,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(3))\n",
    "    model.add(Conv1D(64, 5, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))  # Ajuste para o número de classes\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a481f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando Fold 1\n",
      "aqui\n",
      "aqui\n",
      "(75, 88200, 1) (75,)\n",
      "modelo 1\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 28s 9s/step - loss: 209.3514 - accuracy: 0.1600 - val_loss: 2.2076 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 21s 4s/step - loss: 164.6193 - accuracy: 0.3467 - val_loss: 4.9130 - val_accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 13s 4s/step - loss: 80.9488 - accuracy: 0.6000 - val_loss: 8.6548 - val_accuracy: 0.2500\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 54.2669 - accuracy: 0.5600 - val_loss: 15.3983 - val_accuracy: 0.2500\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 60.2377 - accuracy: 0.6267 - val_loss: 25.3241 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 23.9903 - accuracy: 0.6800 - val_loss: 37.2838 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 20.7633 - accuracy: 0.6267 - val_loss: 51.1799 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 18.2230 - accuracy: 0.7467 - val_loss: 64.6789 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 23.9864 - accuracy: 0.7067 - val_loss: 79.2133 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 13s 4s/step - loss: 25.8987 - accuracy: 0.6933 - val_loss: 94.9411 - val_accuracy: 0.0000e+00\n",
      "acabei modelo1\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Fold 1 Accuracy: 0.25\n",
      "Processando Fold 2\n",
      "aqui\n",
      "aqui\n",
      "(75, 88200, 1) (75,)\n",
      "modelo 2\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 14s 4s/step - loss: 203.0461 - accuracy: 0.1467 - val_loss: 4.7249 - val_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 11s 3s/step - loss: 177.8776 - accuracy: 0.4400 - val_loss: 4.8098 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 168.8520 - accuracy: 0.4533 - val_loss: 3.8180 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 53.7170 - accuracy: 0.5867 - val_loss: 5.6327 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 56.3914 - accuracy: 0.6933 - val_loss: 10.9154 - val_accuracy: 0.2500\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 50.3553 - accuracy: 0.6000 - val_loss: 18.7465 - val_accuracy: 0.2500\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 23.3541 - accuracy: 0.7867 - val_loss: 25.3105 - val_accuracy: 0.2500\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 33.3548 - accuracy: 0.6933 - val_loss: 35.2062 - val_accuracy: 0.2500\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 33.6654 - accuracy: 0.7867 - val_loss: 45.9325 - val_accuracy: 0.2500\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 12s 3s/step - loss: 10.7016 - accuracy: 0.8267 - val_loss: 55.8436 - val_accuracy: 0.2500\n",
      "acabei modelo2\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "Fold 2 Accuracy: 0.0\n",
      "Processando Fold 3\n",
      "aqui\n",
      "aqui\n",
      "(74, 88200, 1) (74,)\n",
      "modelo 3\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 18s 5s/step - loss: 157.9424 - accuracy: 0.1081 - val_loss: 2.6217 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "def process_audio_paths(paths):\n",
    "    processed_audios = []\n",
    "    for path in paths:\n",
    "        audio, _ = librosa.load(path, sr=22050, duration=4.0)\n",
    "        audio = librosa.util.fix_length(audio, size=22050 * 4)\n",
    "        processed_audios.append(audio)\n",
    "    # Transforma a lista de arrays em um único array NumPy 3D\n",
    "    return np.array(processed_audios).reshape(-1, 88200, 1)\n",
    "\n",
    "results = []\n",
    "histories=[]\n",
    "\n",
    "for i in range(1, 11):\n",
    "    print(f\"Processando Fold {i}\")\n",
    "    \n",
    "    # Processa os caminhos dos áudios\n",
    "    test_paths = fold_data[f'fold{i}']['paths']\n",
    "    test_labels = fold_data[f'fold{i}']['labels']\n",
    "    print(\"aqui\")\n",
    "    train_paths = [path for fold, data in fold_data.items() if fold != f'fold{i}' for path in data['paths']]\n",
    "    train_labels = [label for fold, data in fold_data.items() if fold != f'fold{i}' for label in data['labels']]\n",
    "    print(\"aqui\")\n",
    "    X_train = process_audio_paths(train_paths)\n",
    "    X_test = process_audio_paths(test_paths)\n",
    "    y_train = np.array(train_labels)\n",
    "    y_test = np.array(test_labels)\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    # Dividir o conjunto de teste em metades iguais para teste e validação\n",
    "    split_index = len(X_test) // 2\n",
    "    X_val, y_val = X_test[:split_index], y_test[:split_index]\n",
    "    X_test, y_test = X_test[split_index:], y_test[split_index:]\n",
    "\n",
    "    # Criação e treinamento do modelo\n",
    "    print(f\"modelo {i}\")\n",
    "    model = create_model((len(X_train), 1))  # Ajuste as dimensões conforme necessário\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "    print(f\"acabei modelo{i}\")\n",
    "    # Avaliação do modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    histories.append(history.history)\n",
    "    results.append(accuracy_score(y_test, y_pred_classes))\n",
    "\n",
    "    # Imprimir resultados do fold atual\n",
    "    print(f\"Fold {i} Accuracy: {results[-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc069379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Média das acurácias\n",
    "average_accuracy = np.mean(results)\n",
    "print(f\"Average Accuracy: {average_accuracy}\")\n",
    "\n",
    "# Desvio padrão das acurácias\n",
    "std_dev_accuracy = np.std(results)\n",
    "print(f\"Standard Deviation of Accuracy: {std_dev_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8374e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotar gráficos para o último fold como exemplo\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd7b8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
