{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac51a7bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "this version of pandas is incompatible with numpy < 1.20.3\nyour numpy version is 1.20.0.\nPlease upgrade numpy to >= 1.20.3 to use this pandas version",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Importação de Bibliotecas Necessárias\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/__init__.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev  \u001b[38;5;66;03m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/compat/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     is_numpy_dev,\n\u001b[1;32m     20\u001b[0m     np_version_under1p21,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     pa_version_under1p01,\n\u001b[1;32m     24\u001b[0m     pa_version_under2p0,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     pa_version_under9p0,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/compat/numpy/__init__.py:23\u001b[0m\n\u001b[1;32m     19\u001b[0m     np_percentile_argname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterpolation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _nlv \u001b[38;5;241m<\u001b[39m Version(_min_numpy_ver):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis version of pandas is incompatible with numpy < \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_min_numpy_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour numpy version is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_np_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease upgrade numpy to >= \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_min_numpy_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to use this pandas version\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m     )\n\u001b[1;32m     30\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_np_version\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_numpy_dev\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m ]\n",
      "\u001b[0;31mImportError\u001b[0m: this version of pandas is incompatible with numpy < 1.20.3\nyour numpy version is 1.20.0.\nPlease upgrade numpy to >= 1.20.3 to use this pandas version"
     ]
    }
   ],
   "source": [
    "# Importação de Bibliotecas Necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ff2e8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.3810263e+02  1.8237880e+02 -8.0175827e+01 ... -4.3171391e+00\n",
      "  -4.4397454e+00 -4.0319953e+00]\n",
      " [-2.0318384e+02  1.9251834e+02 -1.5561098e+02 ...  3.9403834e+00\n",
      "  -1.0747721e+00 -2.1122086e-01]\n",
      " [-2.3871693e+02  1.0732930e+02 -3.6585022e+01 ... -5.3374166e+00\n",
      "  -1.3342643e+00 -2.5891340e+00]\n",
      " ...\n",
      " [-4.2917862e+02  1.2991762e+02 -8.3397408e+00 ...  2.9807186e+00\n",
      "  -1.0773857e+00 -6.8800771e-01]\n",
      " [-1.6679102e+02  7.2151688e+01 -3.6855282e+01 ...  3.4777620e+00\n",
      "  -5.8632250e+00 -3.3734778e-01]\n",
      " [-3.7684305e+02  1.1927762e+02 -7.5979164e+01 ... -1.3372263e+00\n",
      "  -7.2432613e-01  2.6398787e+00]]\n"
     ]
    }
   ],
   "source": [
    "import soundata\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Inicializar e baixar o conjunto de dados UrbanSound8K\n",
    "dataset = soundata.initialize('urbansound8k')\n",
    "#dataset.download()  # Baixar o dataset\n",
    "#dataset.validate()  # Validar a presença de todos os arquivos esperados\n",
    "\n",
    "# Função para extrair características (exemplo: MFCC)\n",
    "def extract_features(audio_data, sample_rate):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "    return mfccs_processed\n",
    "\n",
    "# Lista para armazenar as características e rótulos\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Iterar sobre os exemplos do conjunto de dados\n",
    "for clip in dataset.clip_ids:\n",
    "    audio_clip = dataset.clip(clip)\n",
    "    \n",
    "    # Carregar os dados de áudio e a taxa de amostragem\n",
    "    audio_data, sample_rate = audio_clip.audio\n",
    "\n",
    "    # Extrair características\n",
    "    data = extract_features(audio_data, sample_rate)\n",
    "\n",
    "    # Adicionar características e rótulo à lista\n",
    "    features.append(data)\n",
    "    tags=audio_clip.tags\n",
    "    labels.append(tags.labels[np.argmax(tags.confidence)])\n",
    "\n",
    "# Convertendo listas em arrays NumPy\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(features)\n",
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "#X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da930a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas únicas no conjunto de dados: ['children_playing' 'gun_shot' 'air_conditioner' 'jackhammer' 'drilling'\n",
      " 'engine_idling' 'dog_bark' 'siren' 'street_music' 'car_horn']\n"
     ]
    }
   ],
   "source": [
    "df_features = pd.DataFrame(features)\n",
    "\n",
    "# Adicionar os rótulos ao DataFrame\n",
    "df_features['label'] = labels\n",
    "\n",
    "unique_labels = df_features['label'].unique()\n",
    "print(\"Etiquetas únicas no conjunto de dados:\", unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de1304b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audio_clip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Audio\n\u001b[0;32m----> 2\u001b[0m tags \u001b[38;5;241m=\u001b[39m \u001b[43maudio_clip\u001b[49m\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Se você quiser todas as etiquetas\u001b[39;00m\n\u001b[1;32m      5\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m tags\u001b[38;5;241m.\u001b[39mlabels\n",
      "\u001b[0;31mNameError\u001b[0m: name 'audio_clip' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "tags = audio_clip.tags\n",
    "\n",
    "# Se você quiser todas as etiquetas\n",
    "all_labels = tags.labels\n",
    "\n",
    "# Se você quiser a etiqueta com maior confiança\n",
    "max_confidence_index = np.argmax(tags.confidence)\n",
    "label_with_highest_confidence = tags.labels[max_confidence_index]\n",
    "\n",
    "print(\"Todas as etiquetas:\", all_labels)\n",
    "print(\"Etiqueta com maior confiança:\", label_with_highest_confidence)\n",
    "Audio(data=audio_data, rate=sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5b118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modelo de Classificação de Deep Learning\n",
    "# (Este é um esboço básico. Deve-se ajustar a arquitetura e os parâmetros conforme necessário)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(...)))  # Adicionar as dimensões corretas\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))  # 10 classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Treinamento e Validação do Modelo\n",
    "# (Adicionar código para treinar e validar o modelo, incluindo a divisão dos dados em conjuntos de treino e teste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a831f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados em treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Codificação dos rótulos\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Divisão dos dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Conversão dos rótulos para formato categórico\n",
    "y_train_categorical = to_categorical(y_train, num_classes=len(unique_labels))\n",
    "y_test_categorical = to_categorical(y_test, num_classes=len(unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f9f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição da arquitetura do modelo CNN\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(features.shape[1], 1)))  # Usando entrada 1D\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(unique_labels), activation='softmax'))  # Número de classes\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "history = model.fit(X_train, y_train_categorical, epochs=10, batch_size=32, validation_data=(X_test, y_test_categorical))\n",
    "\n",
    "# Avaliação do modelo\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical)\n",
    "print(\"Acurácia no conjunto de teste:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
