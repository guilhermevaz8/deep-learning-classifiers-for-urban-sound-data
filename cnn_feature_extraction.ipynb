{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extration for the Convolutional Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries and setting some variables that we will be wanting to use for all the features' extraction processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedures to save and load extracted data from and to the disk\n",
    "\n",
    "Throughout this notebook, we will be using the following procedures to save steps of our processed data into the disk, such that we can load it later if we need to.\n",
    "\n",
    "These functions take advantage of Python's library _Pickle_, which allow us to save the content of our variables in binary files of extension _.pkl_, and to load them with the structure that it was saved from (dictionary, NumPy array, class object, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pkl(data, path):\n",
    "    with open(path, \"wb\") as saved_data:\n",
    "        pickle.dump(data, saved_data)\n",
    "    saved_data.close()\n",
    "\n",
    "def load_pkl(path):\n",
    "    to_return = None\n",
    "    with open(path, \"rb\") as loaded_data:\n",
    "        to_return = pickle.load(loaded_data)\n",
    "    loaded_data.close()\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data's Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>99812-1-2-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>159.522205</td>\n",
       "      <td>163.522205</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>99812-1-3-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>181.142431</td>\n",
       "      <td>183.284976</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>99812-1-4-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>242.691902</td>\n",
       "      <td>246.197885</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>99812-1-5-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>253.209850</td>\n",
       "      <td>255.741948</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>99812-1-6-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>332.289233</td>\n",
       "      <td>334.821332</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8732 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         slice_file_name    fsID       start         end  salience  fold  \\\n",
       "0       100032-3-0-0.wav  100032    0.000000    0.317551         1     5   \n",
       "1     100263-2-0-117.wav  100263   58.500000   62.500000         1     5   \n",
       "2     100263-2-0-121.wav  100263   60.500000   64.500000         1     5   \n",
       "3     100263-2-0-126.wav  100263   63.000000   67.000000         1     5   \n",
       "4     100263-2-0-137.wav  100263   68.500000   72.500000         1     5   \n",
       "...                  ...     ...         ...         ...       ...   ...   \n",
       "8727     99812-1-2-0.wav   99812  159.522205  163.522205         2     7   \n",
       "8728     99812-1-3-0.wav   99812  181.142431  183.284976         2     7   \n",
       "8729     99812-1-4-0.wav   99812  242.691902  246.197885         2     7   \n",
       "8730     99812-1-5-0.wav   99812  253.209850  255.741948         2     7   \n",
       "8731     99812-1-6-0.wav   99812  332.289233  334.821332         2     7   \n",
       "\n",
       "      classID             class  \n",
       "0           3          dog_bark  \n",
       "1           2  children_playing  \n",
       "2           2  children_playing  \n",
       "3           2  children_playing  \n",
       "4           2  children_playing  \n",
       "...       ...               ...  \n",
       "8727        1          car_horn  \n",
       "8728        1          car_horn  \n",
       "8729        1          car_horn  \n",
       "8730        1          car_horn  \n",
       "8731        1          car_horn  \n",
       "\n",
       "[8732 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_info = pd.read_csv(\"UrbanSound8K.csv\")\n",
    "data_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling and Zero Padding\n",
    "\n",
    "Firstly, we will resample all of our audio raw data such that the resulting data has a sample rate of 44.1 KHz. We will also zero-pad it such that all data points represent audio with 4 seconds of duration.\n",
    "\n",
    "All data will be saved seperately by fold.\n",
    "\n",
    "We will also save the corresponding .wav file name such that we can correctly obtain its fold and classification in the dataset metadata CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS_PATH = \"../UrbanSound8K/audio/\"\n",
    "DURATION = 4 # 4 seconds for each audio file\n",
    "SAMPLE_RATE = 44100\n",
    "HOP_LENGTH = round(SAMPLE_RATE * 0.0125)\n",
    "WIN_LENGTH = round(SAMPLE_RATE * 0.023)\n",
    "N_FFT = 2**10\n",
    "TIME_SIZE = 4*SAMPLE_RATE//HOP_LENGTH+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(audio_file_path):\n",
    "    signal, sample_rate = librosa.load(audio_file_path, sr=None)\n",
    "    # resample the sample rate to the target value of SR\n",
    "    signal = librosa.resample(signal, orig_sr=sample_rate, target_sr=SAMPLE_RATE)\n",
    "    # zero padding\n",
    "    if len(signal) < DURATION*SAMPLE_RATE:\n",
    "        signal = np.concatenate([\n",
    "            signal,\n",
    "            np.zeros(shape=(DURATION*SAMPLE_RATE - len(signal), ))\n",
    "        ])\n",
    "    elif len(signal) > DURATION*SAMPLE_RATE:\n",
    "        signal = signal[:DURATION*SAMPLE_RATE]\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold1\n",
      "fold10\n",
      "fold2\n",
      "fold3\n",
      "fold4\n",
      "fold5\n",
      "fold6\n",
      "fold7\n",
      "fold8\n",
      "fold9\n"
     ]
    }
   ],
   "source": [
    "folds = [fold for fold in os.listdir(FOLDS_PATH) if \"fold\" in fold]\n",
    "for fold in folds:\n",
    "    print(fold)\n",
    "    df_data = []\n",
    "    audio_files = librosa.util.find_files(FOLDS_PATH+\"/\"+fold)\n",
    "    for audio_file_path in audio_files:\n",
    "        audio_file = audio_file_path.split(\"\\\\\")[-1]\n",
    "        df_data.append({'id': audio_file, 'zero_padded_data': zero_pad(audio_file_path)})\n",
    "    df = pd.DataFrame(data=df_data, columns=['id', 'zero_padded_data'])\n",
    "    save_pkl(df, f\"features/zero_pad/{fold}_csv.pkl\")\n",
    "    # memory management\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of the 2D features\n",
    "\n",
    "For this task, we will be taking advange of Librosa's library capabilities and extract the following 2D features from the .wav files availavle in the _UrbanSound8K_ dataset:\n",
    "- Chromagram\n",
    "- Mel-scaled Spectogram\n",
    "- Short-time Fourier transform Tempogram\n",
    "\n",
    "The following functions allow us to extract, in order, the beforehand mentioned features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chromagram(audio_data):\n",
    "    N_CHROMA = 12\n",
    "    return librosa.feature.chroma_stft(y=audio_data, n_chroma=N_CHROMA, sr=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_spectogram(audio_data):\n",
    "    return librosa.feature.melspectrogram(y=audio_data, sr=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_tempogram(audio_data):\n",
    "    return np.abs(librosa.feature.fourier_tempogram(y=audio_data, sr=SAMPLE_RATE, hop_length=HOP_LENGTH, win_length=WIN_LENGTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we extract the features and save the obtained data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "/home/guilherme/.local/lib/python3.8/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10+1):\n",
    "    fold = f\"fold{i}\"\n",
    "    fold_df = load_pkl(f\"features/zero_pad/fold{i}_csv.pkl\")\n",
    "    print(fold)\n",
    "    df_extracted_data = []\n",
    "    for i in range(fold_df.shape[0]):\n",
    "        extracted_data = {\n",
    "            'id': fold_df.iloc[i,0],\n",
    "            'chromagram': chromagram(fold_df.iloc[i,1]),\n",
    "            'mel_spectogram': mel_spectogram(fold_df.iloc[i,1]),\n",
    "            'fourier_tempogram': fourier_tempogram(fold_df.iloc[i,1])\n",
    "        }\n",
    "        df_extracted_data.append(extracted_data)\n",
    "    df = pd.DataFrame(data=df_extracted_data, columns=['id', 'chromagram', 'mel_spectogram', 'fourier_tempogram'])\n",
    "    save_pkl(df, f\"features/extracted_2d/extracted_2d_{fold}_csv.pkl\")\n",
    "    # memory management\n",
    "    del fold_df\n",
    "    del df_extracted_data\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of the 1D features\n",
    "\n",
    "We will be taking advange of Librosa's library capabilities once again to extract some 1D features from the .wav files. Here are presented the 1D features to be extracted:\n",
    "- Spectral Centroid\n",
    "- Spectral Bandwidth\n",
    "- Spectral Flatness\n",
    "- Spectral Rolloff\n",
    "\n",
    "The following functions allow us to extract, in order, the beforehand mentioned features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_centroid(audio_data):\n",
    "    return librosa.feature.spectral_centroid(y=audio_data, sr=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_bandwidth(audio_data):\n",
    "    return librosa.feature.spectral_bandwidth(y=audio_data, sr=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_flatness(audio_data):\n",
    "    return librosa.feature.spectral_flatness(y=audio_data, n_fft=N_FFT, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_rolloff(audio_data):\n",
    "    return librosa.feature.spectral_rolloff(y=audio_data, sr=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold1\n",
      "fold2\n",
      "fold3\n",
      "fold4\n",
      "fold5\n",
      "fold6\n",
      "fold7\n",
      "fold8\n",
      "fold9\n",
      "fold10\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10+1):\n",
    "    fold = f\"fold{i}\"\n",
    "    fold_df = load_pkl(f\"features/zero_pad/fold{i}_csv.pkl\")\n",
    "    print(fold)\n",
    "    df_extracted_data = []\n",
    "    for i in range(fold_df.shape[0]):\n",
    "        extracted_data = {\n",
    "            'id': fold_df.iloc[i,0],\n",
    "            'spectral_centroid': spectral_centroid(fold_df.iloc[i,1]),\n",
    "            'spectral_bandwidth': spectral_bandwidth(fold_df.iloc[i,1]),\n",
    "            'spectral_flatness': spectral_flatness(fold_df.iloc[i,1]),\n",
    "            'spectral_rolloff': spectral_rolloff(fold_df.iloc[i,1])\n",
    "        }\n",
    "        df_extracted_data.append(extracted_data)\n",
    "    df = pd.DataFrame(data=df_extracted_data, columns=['id', 'spectral_centroid', 'spectral_bandwidth', 'spectral_flatness', 'spectral_rolloff'])\n",
    "    save_pkl(df, f\"features/extracted_1d/extracted_1d_{fold}_csv.pkl\")\n",
    "    # memory management\n",
    "    del fold_df\n",
    "    del df_extracted_data\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization the data\n",
    "\n",
    "As a last step of our Data Pre-Processing and Feature Extraction phases for our CNN model, we are going to normalize all values extracted, feature by feature, using the Min-Max scalling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D\n",
      "fold1\n",
      "fold2\n",
      "fold3\n",
      "fold4\n",
      "fold5\n",
      "fold6\n",
      "fold7\n",
      "fold8\n",
      "fold9\n",
      "fold10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(\"2D\")\n",
    "for i in range(1,10+1):\n",
    "    fold = f\"fold{i}\"\n",
    "    fold_df: pd.DataFrame = load_pkl(f\"features/extracted_2d/extracted_2d_fold{i}_csv.pkl\")\n",
    "    print(fold)\n",
    "    cols = ['chromagram', 'mel_spectogram', 'fourier_tempogram']\n",
    "    for col in cols:\n",
    "        stacked_values = np.vstack(fold_df[col])\n",
    "        scaler = MinMaxScaler()\n",
    "        normalized_values = scaler.fit_transform(stacked_values)\n",
    "        original_shapes = [value.shape for value in fold_df[col]]\n",
    "        normalized_arrays = [normalized_values[i:i+len(value)].reshape(shape) for i, (value, shape) in enumerate(zip(fold_df[col], original_shapes))]\n",
    "        # update the dataframe column with the normalized values\n",
    "        fold_df[col] = normalized_arrays\n",
    "    fold_df.rename(columns={'id':'slice_file_name'}, inplace=True)\n",
    "    save_pkl(fold_df, f\"features/normalized_feats/norm_feats_2d_{fold}_csv.pkl\")\n",
    "    # memory management\n",
    "    del fold_df\n",
    "    del stacked_values\n",
    "    del normalized_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D\n",
      "fold1\n",
      "fold2\n",
      "fold3\n",
      "fold4\n",
      "fold5\n",
      "fold6\n",
      "fold7\n",
      "fold8\n",
      "fold9\n",
      "fold10\n"
     ]
    }
   ],
   "source": [
    "print(\"1D\")\n",
    "for i in range(1,10+1):\n",
    "    fold = f\"fold{i}\"\n",
    "    fold_df = load_pkl(f\"features/extracted_1d/extracted_1d_fold{i}_csv.pkl\")\n",
    "    print(fold)\n",
    "    cols = ['spectral_centroid', 'spectral_bandwidth', 'spectral_flatness', 'spectral_rolloff']\n",
    "    for col in cols:\n",
    "        stacked_values = np.vstack(fold_df[col])\n",
    "        scaler = MinMaxScaler()\n",
    "        normalized_values = scaler.fit_transform(stacked_values)\n",
    "        original_shapes = [value.shape for value in fold_df[col]]\n",
    "        normalized_arrays = [normalized_values[i:i+len(value)].reshape(shape) for i, (value, shape) in enumerate(zip(fold_df[col], original_shapes))]\n",
    "        # update the dataframe column with the normalized values\n",
    "        fold_df[col] = normalized_arrays\n",
    "    fold_df.rename(columns={'id':'slice_file_name'}, inplace=True)\n",
    "    save_pkl(fold_df, f\"features/normalized_feats/norm_feats_1d_{fold}_csv.pkl\")\n",
    "    # memory management\n",
    "    del fold_df\n",
    "    del stacked_values\n",
    "    del normalized_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the final DataFrames\n",
    "\n",
    "In this set, we merge all the 2D and 1D features we collected into a single dataframe.\n",
    "\n",
    "We also One-Hot encode the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './UrbanSound8K/metadata/UrbanSound8K.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# build the folds dataframes for the cnn training\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m target_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./UrbanSound8K/metadata/UrbanSound8K.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m target_df \u001b[38;5;241m=\u001b[39m target_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslice_file_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassID\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# one hot encode the target class id\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './UrbanSound8K/metadata/UrbanSound8K.csv'"
     ]
    }
   ],
   "source": [
    "# build the folds dataframes for the cnn training\n",
    "\n",
    "target_df = pd.read_csv(\"./UrbanSound8K/metadata/UrbanSound8K.csv\")\n",
    "target_df = target_df[['slice_file_name','classID']]\n",
    "# one hot encode the target class id\n",
    "ohe_targets = np.zeros(shape=(target_df['classID'].size, target_df['classID'].max()+1))\n",
    "ohe_targets[np.arange(target_df['classID'].size), target_df['classID'].to_numpy(dtype=np.int16)] = 1\n",
    "target_df['classID'] = ohe_targets.tolist()\n",
    "target_df['classID'].apply(np.array)\n",
    "\n",
    "# build the folds dataframes\n",
    "for i in range(1, 10+1):\n",
    "    print(f\"fold{i}\")\n",
    "    feat_2d_df = load_pkl(f\"./features/normalized_feats/norm_feats_2d_fold{i}_csv.pkl\")\n",
    "    feat_1d_df = load_pkl(f\"./features/normalized_feats/norm_feats_1d_fold{i}_csv.pkl\")\n",
    "    fold_df = pd.merge(left=feat_2d_df, right=feat_1d_df, on=\"slice_file_name\")\n",
    "    fold_df = pd.merge(left=fold_df, right=target_df, on=\"slice_file_name\")\n",
    "    save_pkl(fold_df, f\"./cnn_folds_dataframes/fold{i}_df.pkl\")\n",
    "    # memory management\n",
    "    del feat_2d_df\n",
    "    del feat_1d_df\n",
    "    del fold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
